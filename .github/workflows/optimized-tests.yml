name: Optimized Test Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  # Test gruplarını parçalara ayırma
  test-setup:
    runs-on: ubuntu-latest
    outputs:
      test-chunks: ${{ steps.split-tests.outputs.test-chunks }}
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest
    
    # Test gruplarını tanımla ve parçalara ayır
    - name: Split tests into chunks
      id: split-tests
      run: |
        # Tüm test dosyalarını bul ve grupla
        TEST_FILES=$(find tests -name "test_*.py" | sort)
        TEST_COUNT=$(echo "$TEST_FILES" | wc -l)
        
        # Test gruplarını oluştur
        CHUNKS=5
        if [ $TEST_COUNT -lt $CHUNKS ]; then
          CHUNKS=$TEST_COUNT
        fi
        
        # Test gruplarını JSON formatında hazırla
        echo "test-chunks<<EOF" >> $GITHUB_OUTPUT
        python -c "
        import json
        import math
        
        test_files = '''$TEST_FILES'''.strip().split('\n')
        chunks = $CHUNKS
        chunk_size = math.ceil(len(test_files) / chunks)
        
        test_chunks = []
        for i in range(0, len(test_files), chunk_size):
            test_chunks.append(test_files[i:i + chunk_size])
        
        print(json.dumps(test_chunks))
        " >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT

  # Her test grubu için paralel çalışacak job'lar
  parallel-tests:
    needs: test-setup
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11']  # Python 3.10+ ile scipy uyumlu
        chunk: ${{ fromJson(needs.test-setup.outputs.test-chunks) }}
      # Hata durumunda diğer testlerin çalışmaya devam etmesi
      fail-fast: false
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          
      redis:
        image: redis:latest
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
        cache-dependency-path: |
          requirements*.txt
          pyproject.toml
          setup.py
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-xdist pytest-cov pytest-timeout
        pip install numpy pandas scipy
        pip install sqlalchemy psycopg2-binary redis
        pip install -e .
    
    - name: Run tests in parallel
      env:
        DB_HOST: localhost
        DB_PORT: 5432
        DB_USER: postgres
        DB_PASSWORD: postgres
        DB_NAME: test_db
        REDIS_HOST: localhost
        REDIS_PORT: 6379
      run: |
        # Test dosyalarını parametre olarak verelim
        TEST_FILES="${{ join(matrix.chunk, ' ') }}"
        
        # Test coverage dosyası için benzersiz isim oluştur
        COVERAGE_FILE="coverage-${{ matrix.python-version }}-${{ strategy.job-index }}.xml"
        
        # Test gruplarını paralel olarak çalıştır
        python -m pytest $TEST_FILES \
          -v \
          --cov=sqlproxy \
          --cov-report=xml:$COVERAGE_FILE \
          -n auto \
          --dist loadscope \
          --timeout=300
        
        # Dosyanın oluşturulduğunu doğrula
        if [ -f "$COVERAGE_FILE" ]; then
          echo "Coverage file created: $COVERAGE_FILE"
        else
          echo "Warning: Coverage file not created!"
          touch $COVERAGE_FILE  # Boş bir dosya oluştur
        fi
    
    - name: Upload partial coverage
      uses: actions/upload-artifact@v3
      with:
        name: coverage-${{ matrix.python-version }}-${{ strategy.job-index }}
        path: coverage-${{ matrix.python-version }}-${{ strategy.job-index }}.xml
        if-no-files-found: warn  # Dosya bulunamazsa uyarı ver ama hata verme

  # Coverage raporlarını birleştir
  merge-coverage:
    needs: parallel-tests
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'  # Scipy için Python 3.10+
    
    - name: Install coverage tools
      run: |
        python -m pip install --upgrade pip
        pip install coverage
    
    - name: Download all coverage reports
      uses: actions/download-artifact@v3
      with:
        path: coverage-reports
    
    - name: List downloaded files
      run: |
        ls -la coverage-reports/
        find coverage-reports -type f -name "*.xml"
    
    - name: Merge coverage reports
      run: |
        if [ -n "$(find coverage-reports -name '*.xml')" ]; then
          coverage combine $(find coverage-reports -name '*.xml')
          coverage xml -o coverage.xml
          coverage report
        else
          echo "No coverage files found to merge!"
          exit 1
        fi
    
    - name: Upload combined coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: false  # Hata olursa bile başarısız sayma